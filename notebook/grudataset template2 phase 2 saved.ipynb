{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge numpy=1.26.4 pandas=2.3.3 scipy=1.15.3 scikit-learn=1.7.2 matplotlib=3.10.6 seaborn=0.13.2 pytorch=2.5.1 torchvision=0.20.1 torchaudio=2.5.1 ipython ipykernel tqdm psutil pyyaml -y && pip install accelerate==1.11.0 aiohappyeyeballs==2.6.1 aiohttp==3.12.15 aiosignal==1.4.0 alembic==1.17.0 annotated-types==0.7.0 anyio==4.11.0 attrs==25.3.0 Authlib==1.6.5 blinker==1.9.0 cachetools==6.2.2 certifi==2025.11.12 charset-normalizer==3.4.4 click==8.3.0 cloudpickle==3.1.2 colorama==0.4.6 colorlog==6.10.1 cryptography==45.0.7 cyclopts==3.24.0 datasets==4.1.1 dill==0.4.0 dnspython==2.8.0 docker==7.1.0 docstring_parser==0.17.0 evaluate==0.4.6 fastapi==0.119.0 Flask==3.1.2 flask-cors==6.0.1 fsspec==2025.9.0 ftfy==6.3.1 GitPython==3.1.45 google-api-core==2.29.0 google-auth==2.41.1 google-cloud-bigquery==3.40.0 google-cloud-core==2.5.0 graphene==3.4.3 grpcio==1.76.0 httpx==0.28.1 huggingface-hub==0.35.1 imbalanced-learn==0.14.0 joblib==1.5.2 kornia==0.8.1 lightning-utilities==0.15.2 mlflow==3.6.0 multiprocess==0.70.16 networkx open_clip_torch==3.2.0 optuna==4.5.0 pillow==12.0.0 protobuf==6.33.4 pydantic==2.12.0 pydantic-settings==2.11.0 pyarrow==21.0.0 regex==2025.9.18 rich==14.2.0 safetensors==0.6.2 SQLAlchemy==2.0.44 starlette==0.48.0 sympy==1.13.1 timm==1.0.20 tokenizers==0.22.1 transformers==4.57.1 uvicorn==0.37.0 waitress==3.0.2 xgboost==3.0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a8cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1600488, 135)\n",
      "    row_id  subject_id   stay_id  hr           starttime             endtime  \\\n",
      "0  3907981    17371178  30001396   0 2147-10-18 13:00:00 2147-10-18 14:00:00   \n",
      "1  1645739    17371178  30001396   1 2147-10-18 14:00:00 2147-10-18 15:00:00   \n",
      "2  4154575    17371178  30001396   1 2147-10-18 14:00:00 2147-10-18 15:00:00   \n",
      "3  4550179    17371178  30001396   1 2147-10-18 14:00:00 2147-10-18 15:00:00   \n",
      "4  2506459    17371178  30001396   2 2147-10-18 15:00:00 2147-10-18 16:00:00   \n",
      "\n",
      "   age  height  weight  gender  ...  respiration  coagulation  liver  \\\n",
      "0   40     NaN   162.1     NaN  ...            0            0      0   \n",
      "1   40     NaN   162.1     NaN  ...            0            0      0   \n",
      "2   40     NaN   162.1     NaN  ...            0            0      0   \n",
      "3   40     NaN   162.1     NaN  ...            0            0      0   \n",
      "4   40     NaN   162.1     NaN  ...            0            0      0   \n",
      "\n",
      "   cardiovascular  cns  renal  hours_beforesepsis  sepsis  fod  \\\n",
      "0               0    1      0                   0       0    0   \n",
      "1               0    1      0                   0       0    0   \n",
      "2               0    1      0                   0       0    0   \n",
      "3               0    1      0                   0       0    0   \n",
      "4               0    1      0                   0       0    0   \n",
      "\n",
      "   hours_beforedeath  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "\n",
      "[5 rows x 135 columns]\n",
      "Shape: (413302, 135)\n",
      "    row_id  subject_id   stay_id  hr           starttime             endtime  \\\n",
      "0  3907986    11206784  30003372   0 2170-06-10 03:00:00 2170-06-10 04:00:00   \n",
      "1  3671749    11206784  30003372   2 2170-06-10 05:00:00 2170-06-10 06:00:00   \n",
      "2  4469738    11206784  30003372   2 2170-06-10 05:00:00 2170-06-10 06:00:00   \n",
      "3   362754    11206784  30003372   3 2170-06-10 06:00:00 2170-06-10 07:00:00   \n",
      "4  3159772    11206784  30003372   3 2170-06-10 06:00:00 2170-06-10 07:00:00   \n",
      "\n",
      "   age  height  weight  gender  ...  respiration  coagulation  liver  \\\n",
      "0   38     NaN   135.0     NaN  ...            0            0      0   \n",
      "1   38     NaN   135.0     NaN  ...            0            0      0   \n",
      "2   38     NaN   135.0     NaN  ...            0            0      0   \n",
      "3   38     NaN   135.0     NaN  ...            0            0      0   \n",
      "4   38     NaN   135.0     NaN  ...            0            0      0   \n",
      "\n",
      "   cardiovascular  cns  renal  hours_beforesepsis  sepsis  fod  \\\n",
      "0               0    0      1                   0       0    0   \n",
      "1               0    0      1                   0       0    0   \n",
      "2               0    0      1                   0       0    0   \n",
      "3               0    0      1                   0       0    0   \n",
      "4               0    0      1                   0       0    0   \n",
      "\n",
      "   hours_beforedeath  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"/root/df_train30.parquet\"\n",
    "\n",
    "df_train = pq.read_table(train_path)\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "print(\"Shape:\", df_train.shape)\n",
    "print(df_train.head())\n",
    "\n",
    "val_path = \"/root/df_val30.parquet\"\n",
    "\n",
    "df_val = pq.read_table(val_path)\n",
    "df_val = df_val.to_pandas()\n",
    "\n",
    "print(\"Shape:\", df_val.shape)\n",
    "print(df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e60239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74297631",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = [\n",
    "    \"respiration\",\n",
    "    \"coagulation\",\n",
    "    \"liver\",\n",
    "    \"cardiovascular\",\n",
    "    \"cns\",\n",
    "    \"renal\",\n",
    "    \"hours_beforesepsis\",\n",
    "    \"sepsis\",\n",
    "    \"fod\",\n",
    "    \"hours_beforedeath\"\n",
    "]\n",
    "\n",
    "non_output_cols = df_train.columns.difference(output_cols)\n",
    "\n",
    "# df_train[\"hours_beforesepsis\"] = df_train[\"hours_beforesepsis\"].fillna(0)\n",
    "# df_train['gender'] = df_train['gender'].map({'M':0, 'F':1})\n",
    "\n",
    "# for col in df_train.select_dtypes(include=['object']).columns:\n",
    "#     df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# df_val[\"hours_beforesepsis\"] = df_val[\"hours_beforesepsis\"].fillna(0)\n",
    "# df_val['gender'] = df_val['gender'].map({'M':0, 'F':1})\n",
    "\n",
    "# for col in df_val.select_dtypes(include=['object']).columns:\n",
    "#     df_val[col] = pd.to_numeric(df_val[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af39b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_cols = [\"respiration\", \"coagulation\", \"liver\", \"cardiovascular\", \n",
    "                   \"cns\", \"renal\", \"hours_beforesepsis\", \"hours_beforedeath\"]\n",
    "binary_cols = [\"sepsis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6fd410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train = df_train[non_output_cols].drop(columns=[\"starttime\", \"endtime\", \"subject_id\", \"row_id\"]).to_numpy(dtype=np.float32)\n",
    "y_train_reg = df_train[regression_cols].to_numpy(dtype=np.float32)\n",
    "y_train_bin = df_train[binary_cols].to_numpy(dtype=np.int32)\n",
    "stay_ids_train = df_train['stay_id'].values\n",
    "times_train = df_train.groupby(\"stay_id\").cumcount().values\n",
    "\n",
    "# Val\n",
    "X_val = df_val[non_output_cols].drop(columns=[\"starttime\", \"endtime\", \"subject_id\", \"row_id\"]).to_numpy(dtype=np.float32)\n",
    "y_val_reg = df_val[regression_cols].to_numpy(dtype=np.float32)\n",
    "y_val_bin = df_val[binary_cols].to_numpy(dtype=np.int32)\n",
    "stay_ids_val = df_val['stay_id'].values\n",
    "times_val = df_val.groupby(\"stay_id\").cumcount().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "\n",
    "# n_train, n_features = X_train.shape\n",
    "\n",
    "# X_train_scaled = np.memmap(\n",
    "#     \"X_train_scaled2.dat\",   \n",
    "#     dtype=\"float32\",\n",
    "#     mode=\"w+\",\n",
    "#     shape=(n_train, n_features)\n",
    "# )\n",
    "\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_X.fit(X_train.astype(np.float32))\n",
    "\n",
    "# chunk_size = 100_000\n",
    "# for start in range(0, n_train, chunk_size):\n",
    "#     end = min(start + chunk_size, n_train)\n",
    "#     X_train_scaled[start:end] = scaler_X.transform(\n",
    "#         X_train[start:end].astype(np.float32)\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_val = X_val.shape[0]\n",
    "\n",
    "# X_val_scaled = np.memmap(\n",
    "#     \"X_val_scaled3.dat\",\n",
    "#     dtype=\"float32\",\n",
    "#     mode=\"w+\",\n",
    "#     shape=(n_val, n_features)\n",
    "# )\n",
    "\n",
    "# for start in range(0, n_val, chunk_size):\n",
    "#     end = min(start + chunk_size, n_val)\n",
    "#     X_val_scaled[start:end] = scaler_X.transform(\n",
    "#         X_val[start:end].astype(np.float32)\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler_y_reg = StandardScaler()\n",
    "# y_train_reg_scaled = scaler_y_reg.fit_transform(y_train_reg)\n",
    "# y_val_reg_scaled = scaler_y_reg.transform(y_val_reg)\n",
    "\n",
    "# # Binary targets\n",
    "# y_train_bin_scaled = y_train_bin\n",
    "# y_val_bin_scaled = y_val_bin\n",
    "\n",
    "# # Gabungkan kembali\n",
    "# y_train_scaled = np.concatenate([y_train_reg_scaled, y_train_bin_scaled], axis=1)\n",
    "# y_val_scaled = np.concatenate([y_val_reg_scaled, y_val_bin_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e977c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Global feature mean\n",
    "# global_feat_mean = np.nanmean(X_train_scaled, axis=0)\n",
    "# global_feat_mean = np.nan_to_num(global_feat_mean, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "560a620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All joblib pkl loaded ✅\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "scaler_X = joblib.load(\"scaler_X.pkl\")\n",
    "scaler_y_reg = joblib.load(\"scaler_y_reg.pkl\")\n",
    "global_feat_mean = np.load(\"global_feat_mean.npy\")\n",
    "\n",
    "print(\"All joblib pkl loaded ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46c8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_features = X_train.shape\n",
    "\n",
    "X_train_scaled = np.memmap(\n",
    "    \"X_train_scaled2.dat\",\n",
    "    dtype=\"float32\",\n",
    "    mode=\"r\",\n",
    "    shape=(n_train, n_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7d3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val, n_features = X_val.shape\n",
    "\n",
    "X_val_scaled = np.memmap(\n",
    "    \"X_val_scaled2.dat\",\n",
    "    dtype=\"float32\",\n",
    "    mode=\"r\",\n",
    "    shape=(n_val, n_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f599f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y_reg.fit(y_train_reg)\n",
    "\n",
    "y_train_bin = y_train_bin\n",
    "\n",
    "y_train_reg_scaled = scaler_y_reg.transform(y_train_reg)\n",
    "y_train_bin_scaled = y_train_bin\n",
    "\n",
    "y_train_scaled = np.concatenate(\n",
    "    [y_train_reg_scaled, y_train_bin_scaled],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "y_val_bin = y_val_bin\n",
    "\n",
    "y_val_reg_scaled = scaler_y_reg.transform(y_val_reg)\n",
    "y_val_bin_scaled = y_val_bin\n",
    "\n",
    "y_val_scaled = np.concatenate(\n",
    "    [y_val_reg_scaled, y_val_bin_scaled],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7b9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalWindowDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y,\n",
    "        stay_ids,\n",
    "        times,\n",
    "        global_feat_mean,\n",
    "        window_sizes=(6, 12, 24),\n",
    "        horizon=1\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.global_mean = global_feat_mean\n",
    "        self.samples = []\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"stay_id\": stay_ids,\n",
    "            \"time\": times,\n",
    "            \"idx\": np.arange(len(stay_ids))\n",
    "        })\n",
    "\n",
    "        for stay_id, g in df.groupby(\"stay_id\"):\n",
    "            g = g.sort_values(\"time\")\n",
    "            idxs = g[\"idx\"].values\n",
    "            tvals = g[\"time\"].values\n",
    "\n",
    "            for w in window_sizes:\n",
    "                if len(idxs) <= w + horizon:\n",
    "                    continue\n",
    "                for i in range(w, len(idxs) - horizon):\n",
    "                    hist = idxs[i - w:i]\n",
    "                    target = idxs[i + horizon]\n",
    "                    times_hist = tvals[i - w:i]\n",
    "                    self.samples.append((hist, target, times_hist, w))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hist_idx, target_idx, times, w = self.samples[idx]\n",
    "        window_id = {6: 0, 12: 1, 24: 2}[w]\n",
    "\n",
    "        X_seq = self.X[hist_idx].astype(float)\n",
    "        y_target = self.y[target_idx]\n",
    "\n",
    "        # Pisahin regresi & binary\n",
    "        n_reg = y_train_reg.shape[1]  # jumlah kolom regresi\n",
    "        n_bin = y_train_bin.shape[1]  # jumlah kolom binary\n",
    "\n",
    "        y_reg = y_target[:n_reg].astype(float)\n",
    "        y_bin = y_target[n_reg:].astype(int)  # pastikan integer 0/1\n",
    "\n",
    "        mask = ~np.isnan(X_seq)\n",
    "\n",
    "        T, F = X_seq.shape\n",
    "        X_filled = np.zeros_like(X_seq)\n",
    "        delta = np.zeros_like(X_seq)\n",
    "\n",
    "        for f in range(F):\n",
    "            last_val = self.global_mean[f]\n",
    "            last_time = times[0]\n",
    "            for t in range(T):\n",
    "                if mask[t, f]:\n",
    "                    delta[t, f] = 0.0\n",
    "                    last_val = X_seq[t, f]\n",
    "                    last_time = times[t]\n",
    "                    X_filled[t, f] = last_val\n",
    "                else:\n",
    "                    delta[t, f] = times[t] - last_time\n",
    "                    gamma = np.exp(-delta[t, f])\n",
    "                    X_filled[t, f] = gamma * last_val + (1 - gamma) * self.global_mean[f]\n",
    "                    last_val = X_filled[t, f]\n",
    "\n",
    "        return {\n",
    "            \"X\": torch.tensor(X_filled, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(mask.astype(float), dtype=torch.float32),\n",
    "            \"delta\": torch.tensor(delta, dtype=torch.float32),\n",
    "            \"y_reg\": torch.tensor(y_reg, dtype=torch.float32),\n",
    "            \"y_bin\": torch.tensor(y_bin, dtype=torch.float32),  # bisa float32 untuk BCE\n",
    "            \"window_id\": torch.tensor(window_id, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X_list, mask_list, delta_list, y_reg_list, y_bin_list, window_id_list = [], [], [], [], [], []\n",
    "\n",
    "    max_len = max(item[\"X\"].shape[0] for item in batch)\n",
    "    F = batch[0][\"X\"].shape[1]\n",
    "\n",
    "    for item in batch:\n",
    "        T = item[\"X\"].shape[0]\n",
    "        pad_len = max_len - T\n",
    "\n",
    "        # pad X, mask, delta\n",
    "        X_padded = torch.cat([item[\"X\"], torch.zeros(pad_len, F)], dim=0)\n",
    "        mask_padded = torch.cat([item[\"mask\"], torch.zeros(pad_len, F)], dim=0)\n",
    "        delta_padded = torch.cat([item[\"delta\"], torch.zeros(pad_len, F)], dim=0)\n",
    "\n",
    "        X_list.append(X_padded)\n",
    "        mask_list.append(mask_padded)\n",
    "        delta_list.append(delta_padded)\n",
    "        y_reg_list.append(item[\"y_reg\"])\n",
    "        y_bin_list.append(item[\"y_bin\"])\n",
    "        window_id_list.append(item[\"window_id\"])\n",
    "\n",
    "    return {\n",
    "        \"X\": torch.stack(X_list),\n",
    "        \"mask\": torch.stack(mask_list),\n",
    "        \"delta\": torch.stack(delta_list),\n",
    "        \"y_reg\": torch.stack(y_reg_list),\n",
    "        \"y_bin\": torch.stack(y_bin_list),\n",
    "        \"window_id\": torch.stack(window_id_list),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa7c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TemporalWindowDataset(\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled,\n",
    "    stay_ids=stay_ids_train,\n",
    "    times=times_train,\n",
    "    global_feat_mean=global_feat_mean,\n",
    "    window_sizes=(6, 12, 24),\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "val_dataset = TemporalWindowDataset(\n",
    "    X=X_val_scaled,\n",
    "    y=y_val_scaled,\n",
    "    stay_ids=stay_ids_val,\n",
    "    times=times_val,\n",
    "    global_feat_mean=global_feat_mean,\n",
    "    window_sizes=(6, 12, 24),\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a40273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttnPool(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.score = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, z, padding_mask):\n",
    "        scores = self.score(z).squeeze(-1)  # [B, T]\n",
    "        scores = scores.masked_fill(~padding_mask, -1e9)\n",
    "        alpha = torch.softmax(scores, dim=1)\n",
    "        pooled = (z * alpha.unsqueeze(-1)).sum(dim=1)\n",
    "        return pooled\n",
    "\n",
    "# ===== GRUD Transformer =====\n",
    "class GRUDTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features,\n",
    "        hidden_size=96,\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        reg_dim=8,\n",
    "        bin_dim=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = n_features * 3  # x + mask + delta\n",
    "        self.gru = nn.GRU(self.input_size, hidden_size, batch_first=True)\n",
    "        self.to_dmodel = nn.Linear(hidden_size, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.attn_pool = TemporalAttnPool(d_model)\n",
    "\n",
    "        # ===== 6-head setup =====\n",
    "        self.reg_heads = nn.ModuleList([nn.Linear(d_model, reg_dim) for _ in range(3)])  # regression per window\n",
    "        self.bin_heads = nn.ModuleList([nn.Linear(d_model, bin_dim) for _ in range(3)])  # binary per window\n",
    "\n",
    "        # buat loop mudah untuk freeze/unfreeze\n",
    "        self.heads = nn.ModuleList(self.reg_heads + self.bin_heads)  # total 6 head\n",
    "\n",
    "    def forward(self, x, mask, delta, window_id=None):\n",
    "        inp = torch.cat([x, mask, delta], dim=-1)\n",
    "        h, _ = self.gru(inp)\n",
    "        z = self.to_dmodel(h)\n",
    "\n",
    "        time_mask = mask.sum(dim=-1) > 0\n",
    "        z = self.transformer(z, src_key_padding_mask=~time_mask)\n",
    "        pooled = self.attn_pool(z, padding_mask=~time_mask)\n",
    "\n",
    "        # Ambil output head per sample\n",
    "        y_reg_out = torch.zeros(x.size(0), self.reg_heads[0].out_features, device=x.device)\n",
    "        y_bin_out = torch.zeros(x.size(0), self.bin_heads[0].out_features, device=x.device)\n",
    "\n",
    "        for i, w_id in enumerate(window_id):\n",
    "            y_reg_out[i] = self.reg_heads[w_id](pooled[i])\n",
    "            y_bin_out[i] = self.bin_heads[w_id](pooled[i])\n",
    "\n",
    "        return y_reg_out, y_bin_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec44df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Supports bf16: True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Supports bf16:\", torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66e6cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_scaled.shape[1]\n",
    "reg_dim = y_train_scaled.shape[1] - 1\n",
    "bin_dim = 1\n",
    "\n",
    "model = GRUDTransformer(\n",
    "    n_features=n_features,\n",
    "    hidden_size=64,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    reg_dim=reg_dim,\n",
    "    bin_dim=bin_dim\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad936087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3076/2000963170.py:23: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "use_amp = True\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for head in model.heads:\n",
    "    for p in head.parameters():\n",
    "        p.requires_grad = False\n",
    "for p in model.reg_heads[0].parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.bin_heads[0].parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "for p in model.reg_heads[1].parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.bin_heads[1].parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d2f73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(path, model, optimizer, scheduler, scaler, device):\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "    scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
    "    scaler.load_state_dict(ckpt[\"scaler\"])\n",
    "    return ckpt[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = load_ckpt(\n",
    "    \"ckpt_epoch_5.pt\",\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    scaler,\n",
    "    device\n",
    ")\n",
    "start_epoch = last_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6f38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(path, epoch, model, optimizer, scheduler, scaler):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "        \"scaler\": scaler.state_dict(),\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dc90f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phase(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    epochs,\n",
    "    phase_name=\"\",\n",
    "    use_amp=True,\n",
    "    scaler=scaler,\n",
    "    start_epoch=start_epoch\n",
    "):\n",
    "    criterion_reg = torch.nn.MSELoss(reduction='none')  # per output\n",
    "    criterion_bin = torch.nn.BCEWithLogitsLoss(reduction='none')  # per output\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        train_losses = {0: {\"reg\": 0.0, \"bin\": 0.0}, 1: {\"reg\": 0.0, \"bin\": 0.0}, 2: {\"reg\": 0.0, \"bin\": 0.0}}\n",
    "        train_counts = {0: 0, 1: 0, 2: 0}\n",
    "        train_losses_per_output = {0: [], 1: [], 2: []}  # list of tensor (regression 8 dim)\n",
    "\n",
    "        # ===== TRAIN =====\n",
    "        for batch in tqdm(train_loader, desc=f\"{phase_name} Epoch {epoch+1} [Train]\"):\n",
    "            X = batch[\"X\"].to(device)\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "            delta = batch[\"delta\"].to(device)\n",
    "            y_reg = batch[\"y_reg\"].to(device)\n",
    "            y_bin = batch[\"y_bin\"].to(device)\n",
    "            window_id = batch[\"window_id\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp, dtype=torch.bfloat16):\n",
    "                y_reg_out, y_bin_out = model(X, mask, delta, window_id)\n",
    "                losses = []\n",
    "\n",
    "                for head_idx in window_id.unique():\n",
    "                    idx = (window_id == head_idx)\n",
    "                    if idx.any():\n",
    "                        y_reg_head = y_reg_out[idx]\n",
    "                        y_bin_head = y_bin_out[idx]\n",
    "                        y_reg_target = y_reg[idx]\n",
    "                        y_bin_target = y_bin[idx]\n",
    "\n",
    "                        # per output loss\n",
    "                        reg_loss_per_output = criterion_reg(y_reg_head, y_reg_target).mean(dim=0)  # 8 output\n",
    "                        bin_loss_per_output = criterion_bin(y_bin_head.squeeze(-1), y_bin_target.squeeze(-1))\n",
    "                        bin_loss_per_output = bin_loss_per_output.mean(dim=0) if bin_loss_per_output.dim() > 1 else bin_loss_per_output\n",
    "\n",
    "                        train_losses_per_output[head_idx.item()].append(reg_loss_per_output.cpu())\n",
    "\n",
    "                        # total head loss (avg)\n",
    "                        reg_loss = reg_loss_per_output.mean()\n",
    "                        bin_loss = bin_loss_per_output.mean()\n",
    "\n",
    "                        train_losses[head_idx.item()][\"reg\"] += reg_loss.item()\n",
    "                        train_losses[head_idx.item()][\"bin\"] += bin_loss.item()\n",
    "                        train_counts[head_idx.item()] += 1\n",
    "\n",
    "                        losses.append(reg_loss + bin_loss)\n",
    "\n",
    "                loss = torch.stack(losses).mean()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # avg per head\n",
    "        for h in train_losses:\n",
    "            if train_counts[h] > 0:\n",
    "                train_losses[h][\"reg\"] /= train_counts[h]\n",
    "                train_losses[h][\"bin\"] /= train_counts[h]\n",
    "\n",
    "        # --- PRINT TRAIN LOSS PER OUTPUT ---\n",
    "        print(f\"{phase_name} | Epoch {epoch+1} Train Loss per Head:\")\n",
    "        for h in train_losses:\n",
    "            print(f\"  Head {h}: Reg Loss = {train_losses[h]['reg']:.4f}, Bin Loss = {train_losses[h]['bin']:.4f}\")\n",
    "            # per output (gabungkan semua loss per output jadi satu baris)\n",
    "            if train_losses_per_output[h]:\n",
    "                per_output_mean = torch.stack(train_losses_per_output[h]).mean(dim=0)\n",
    "                loss_str = \", \".join([f\"{l.item():.4f}\" for l in per_output_mean])\n",
    "                print(f\"    Reg Loss per Output: [{loss_str}]\")\n",
    "\n",
    "        # ===== VALIDATION =====\n",
    "        model.eval()\n",
    "        val_losses = {0: {\"reg\": 0.0, \"bin\": 0.0}, 1: {\"reg\": 0.0, \"bin\": 0.0}, 2: {\"reg\": 0.0, \"bin\": 0.0}}\n",
    "        val_counts = {0: 0, 1: 0, 2: 0}\n",
    "        val_losses_per_output = {0: [], 1: [], 2: []}\n",
    "        sepsis_logits, sepsis_true = [], []\n",
    "        reg_preds, reg_true = {0: [], 1: [], 2: []}, {0: [], 1: [], 2: []}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X = batch[\"X\"].to(device)\n",
    "                mask = batch[\"mask\"].to(device)\n",
    "                delta = batch[\"delta\"].to(device)\n",
    "                y_reg = batch[\"y_reg\"].to(device)\n",
    "                y_bin = batch[\"y_bin\"].to(device)\n",
    "                window_id = batch[\"window_id\"].to(device)\n",
    "\n",
    "                y_reg_out, y_bin_out = model(X, mask, delta, window_id)\n",
    "\n",
    "                for head_idx in window_id.unique():\n",
    "                    idx = (window_id == head_idx)\n",
    "                    if idx.any():\n",
    "                        y_reg_head = y_reg_out[idx]\n",
    "                        y_bin_head = y_bin_out[idx]\n",
    "                        y_reg_target = y_reg[idx]\n",
    "                        y_bin_target = y_bin[idx]\n",
    "\n",
    "                        reg_loss_per_output = criterion_reg(y_reg_head, y_reg_target).mean(dim=0)\n",
    "                        bin_loss_per_output = criterion_bin(y_bin_head.squeeze(-1), y_bin_target.squeeze(-1))\n",
    "                        bin_loss_per_output = bin_loss_per_output.mean(dim=0) if bin_loss_per_output.dim() > 1 else bin_loss_per_output\n",
    "\n",
    "                        val_losses_per_output[head_idx.item()].append(reg_loss_per_output.cpu())\n",
    "\n",
    "                        reg_loss = reg_loss_per_output.mean()\n",
    "                        bin_loss = bin_loss_per_output.mean()\n",
    "\n",
    "                        val_losses[head_idx.item()][\"reg\"] += reg_loss.item()\n",
    "                        val_losses[head_idx.item()][\"bin\"] += bin_loss.item()\n",
    "                        val_counts[head_idx.item()] += 1\n",
    "\n",
    "                        sepsis_logits.append(y_bin_head.squeeze(-1).cpu())\n",
    "                        sepsis_true.append(y_bin_target.cpu())\n",
    "\n",
    "                        reg_preds[head_idx.item()].append(y_reg_head.cpu())\n",
    "                        reg_true[head_idx.item()].append(y_reg_target.cpu())\n",
    "\n",
    "        # avg per head\n",
    "        for h in val_losses:\n",
    "            if val_counts[h] > 0:\n",
    "                val_losses[h][\"reg\"] /= val_counts[h]\n",
    "                val_losses[h][\"bin\"] /= val_counts[h]\n",
    "\n",
    "        # --- compute regression metrics per head ---\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        reg_metrics = {}\n",
    "        for h in reg_preds:\n",
    "            if len(reg_preds[h]) > 0:\n",
    "                preds = torch.cat(reg_preds[h], dim=0).numpy()\n",
    "                targets = torch.cat(reg_true[h], dim=0).numpy()\n",
    "                mse = mean_squared_error(targets, preds)\n",
    "                reg_metrics[h] = mse\n",
    "\n",
    "        # --- metrics sepsis ---\n",
    "        sepsis_logits = torch.cat(sepsis_logits).view(-1)\n",
    "        sepsis_true = torch.cat(sepsis_true).view(-1)\n",
    "        sepsis_probs = torch.sigmoid(sepsis_logits)\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "        sepsis_true_np = sepsis_true.cpu().numpy().astype(int)\n",
    "        sepsis_probs_np = sepsis_probs.cpu().numpy().astype(float)\n",
    "        sepsis_preds = (sepsis_probs_np > 0.5).astype(int)\n",
    "        acc = accuracy_score(sepsis_true_np, sepsis_preds)\n",
    "        auc = roc_auc_score(sepsis_true_np, sepsis_probs_np)\n",
    "        cm = confusion_matrix(sepsis_true_np, sepsis_preds)\n",
    "\n",
    "        print(f\"{phase_name} | Epoch {epoch+1} Val Loss per Head:\")\n",
    "        for h in val_losses:\n",
    "            print(f\"  Head {h}: Reg Loss = {val_losses[h]['reg']:.4f}, Bin Loss = {val_losses[h]['bin']:.4f}, MSE = {reg_metrics.get(h, 0):.4f}\")\n",
    "            if val_losses_per_output[h]:\n",
    "                # gabungkan semua loss per output jadi satu baris\n",
    "                per_output_mean = torch.stack(val_losses_per_output[h]).mean(dim=0)\n",
    "                loss_str = \", \".join([f\"{l.item():.4f}\" for l in per_output_mean])\n",
    "                print(f\"    Reg Loss per Output: [{loss_str}]\")\n",
    "\n",
    "        save_ckpt(\n",
    "            path=f\"ckpt_epoch_{epoch}.pt\",\n",
    "            epoch=epoch,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            scaler=scaler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e50b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PHASE 1 (6h) Epoch 6 [Train]:   0%|          | 0/31497 [00:00<?, ?it/s]/tmp/ipykernel_3076/1704097375.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp, dtype=torch.bfloat16):\n",
      "PHASE 1 (6h) Epoch 6 [Train]: 100%|██████████| 31497/31497 [1:10:53<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1 (6h) | Epoch 6 Train Loss per Head:\n",
      "  Head 0: Reg Loss = 0.2887, Bin Loss = 0.0562\n",
      "    Reg Loss per Output: [0.3334, 0.3400, 0.2651, 0.2900, 0.5159, 0.3596, 0.1071, 0.0989]\n",
      "  Head 1: Reg Loss = 0.2071, Bin Loss = 0.0290\n",
      "    Reg Loss per Output: [0.2562, 0.2304, 0.1825, 0.2047, 0.3804, 0.2655, 0.0696, 0.0673]\n",
      "  Head 2: Reg Loss = 0.1523, Bin Loss = 0.0278\n",
      "    Reg Loss per Output: [0.1922, 0.1561, 0.1337, 0.1379, 0.2697, 0.2133, 0.0560, 0.0596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/torch/nn/modules/transformer.py:531: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1 (6h) | Epoch 6 Val Loss per Head:\n",
      "  Head 0: Reg Loss = 0.9729, Bin Loss = 0.9394, MSE = 1.1631\n",
      "    Reg Loss per Output: [0.8163, 0.9773, 0.7414, 0.7995, 0.9163, 0.8696, 1.1869, 1.4756]\n",
      "  Head 1: Reg Loss = 0.8745, Bin Loss = 1.0620, MSE = 1.0698\n",
      "    Reg Loss per Output: [0.6665, 0.8230, 0.6294, 0.5763, 0.7898, 0.7495, 1.2113, 1.5506]\n",
      "  Head 2: Reg Loss = 0.6160, Bin Loss = 1.0362, MSE = 0.8814\n",
      "    Reg Loss per Output: [0.3062, 0.3845, 0.3582, 0.1946, 0.3553, 0.4365, 1.2183, 1.6742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PHASE 1 (6h) Epoch 7 [Train]:   0%|          | 0/31497 [00:00<?, ?it/s]/tmp/ipykernel_3076/1704097375.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp, dtype=torch.bfloat16):\n",
      "PHASE 1 (6h) Epoch 7 [Train]:   3%|▎         | 895/31497 [02:48<1:35:46,  5.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_phase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mphase_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPHASE 1 (6h)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_epoch\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_phase\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, scheduler, device, epochs, phase_name, use_amp, scaler, start_epoch)\u001b[39m\n\u001b[32m     21\u001b[39m train_losses_per_output = {\u001b[32m0\u001b[39m: [], \u001b[32m1\u001b[39m: [], \u001b[32m2\u001b[39m: []}  \u001b[38;5;66;03m# list of tensor (regression 8 dim)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# ===== TRAIN =====\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mphase_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m Epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m [Train]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mTemporalWindowDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     69\u001b[39m     delta[t, f] = times[t] - last_time\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     gamma = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     X_filled[t, f] = gamma * last_val + (\u001b[32m1\u001b[39m - gamma) * \u001b[38;5;28mself\u001b[39m.global_mean[f]\n\u001b[32m     72\u001b[39m     last_val = X_filled[t, f]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_phase(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    phase_name=\"PHASE 1 (6h)\",\n",
    "    use_amp=True,\n",
    "    scaler=scaler,\n",
    "    start_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625f0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
