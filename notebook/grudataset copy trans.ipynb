{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# # Cari semua file parquet batch\n",
    "# parquet_files = glob.glob(\"sepsis_batch_*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9c5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All batches merged! Shape: (7200000, 135)\n"
     ]
    }
   ],
   "source": [
    "# # Baca semua dan gabung\n",
    "# dfs = [pd.read_parquet(f) for f in parquet_files]\n",
    "# df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# # Simpan sekali lagi kalau mau jadi satu file\n",
    "# df_all = df_all.sort_values(by=[\"stay_id\", \"hr\"])\n",
    "# df_all.to_parquet(\"sepsis_full.parquet\", index=False)\n",
    "\n",
    "# print(f\"All batches merged! Shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n ml-env python=3.10 -y && conda activate ml-env && conda install -c conda-forge numpy=1.26.4 pandas=2.3.3 scipy=1.15.3 scikit-learn=1.7.2 matplotlib=3.10.6 seaborn=0.13.2 pytorch=2.5.1 torchvision=0.20.1 torchaudio=2.5.1 ipython ipykernel tqdm psutil pyyaml -y && pip install accelerate==1.11.0 aiohappyeyeballs==2.6.1 aiohttp==3.12.15 aiosignal==1.4.0 alembic==1.17.0 annotated-types==0.7.0 anyio==4.11.0 attrs==25.3.0 Authlib==1.6.5 blinker==1.9.0 cachetools==6.2.2 certifi==2025.11.12 charset-normalizer==3.4.4 click==8.3.0 cloudpickle==3.1.2 colorama==0.4.6 colorlog==6.10.1 cryptography==45.0.7 cyclopts==3.24.0 datasets==4.1.1 dill==0.4.0 dnspython==2.8.0 docker==7.1.0 docstring_parser==0.17.0 evaluate==0.4.6 fastapi==0.119.0 Flask==3.1.2 flask-cors==6.0.1 fsspec==2025.9.0 ftfy==6.3.1 GitPython==3.1.45 google-api-core==2.29.0 google-auth==2.41.1 google-cloud-bigquery==3.40.0 google-cloud-core==2.5.0 graphene==3.4.3 grpcio==1.76.0 httpx==0.28.1 huggingface-hub==0.35.1 imbalanced-learn==0.14.0 joblib==1.5.2 kornia==0.8.1 lightning-utilities==0.15.2 mlflow==3.6.0 multiprocess==0.70.16 networkx open_clip_torch==3.2.0 optuna==4.5.0 pillow==12.0.0 protobuf==6.33.4 pydantic==2.12.0 pydantic-settings==2.11.0 pyarrow==21.0.0 regex==2025.9.18 rich==14.2.0 safetensors==0.6.2 SQLAlchemy==2.0.44 starlette==0.48.0 sympy==1.13.1 timm==1.0.20 tokenizers==0.22.1 transformers==4.57.1 uvicorn==0.37.0 waitress==3.0.2 xgboost==3.0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a8cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000000, 135)\n",
      "    row_id  subject_id   stay_id  hr           starttime             endtime  \\\n",
      "0  1808948    12466550  30000153   1 2174-09-29 13:00:00 2174-09-29 14:00:00   \n",
      "1  1044876    12466550  30000153   4 2174-09-29 16:00:00 2174-09-29 17:00:00   \n",
      "2  1351780    12466550  30000153   4 2174-09-29 16:00:00 2174-09-29 17:00:00   \n",
      "3   606495    12466550  30000153   9 2174-09-29 21:00:00 2174-09-29 22:00:00   \n",
      "4  1645733    12466550  30000153  11 2174-09-29 23:00:00 2174-09-30 00:00:00   \n",
      "\n",
      "   age height  weight gender  ...  respiration  coagulation  liver  \\\n",
      "0   61   None    73.0      M  ...            0            0      0   \n",
      "1   61   None    73.0      M  ...            0            0      0   \n",
      "2   61   None    73.0      M  ...            0            0      0   \n",
      "3   61   None    73.0      M  ...            0            0      0   \n",
      "4   61   None    73.0      M  ...            0            0      0   \n",
      "\n",
      "   cardiovascular  cns  renal  hours_beforesepsis  sepsis  fod  \\\n",
      "0               0    0      0                <NA>       0    0   \n",
      "1               0    0      0                <NA>       0    0   \n",
      "2               0    0      0                <NA>       0    0   \n",
      "3               0    3      0                <NA>       0    0   \n",
      "4               0    3      0                <NA>       0    0   \n",
      "\n",
      "   hours_beforedeath  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"/root/sepsis_full2.parquet\"\n",
    "\n",
    "table = pq.read_table(file_path)\n",
    "df_all = table.to_pandas()\n",
    "\n",
    "print(\"Shape:\", df_all.shape)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc646135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# file_path = r\"C:\\Users\\owen\\PPNinja\\sepsis_batch_1_100000.parquet\"\n",
    "# df_all = pd.read_parquet(file_path)\n",
    "\n",
    "# print(\"Shape:\", df_all.shape)\n",
    "# print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10dd421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = [\n",
    "    \"respiration\",\n",
    "    \"coagulation\",\n",
    "    \"liver\",\n",
    "    \"cardiovascular\",\n",
    "    \"cns\",\n",
    "    \"renal\",\n",
    "    \"hours_beforesepsis\",\n",
    "    \"sepsis\",\n",
    "    \"fod\",\n",
    "    \"hours_beforedeath\"\n",
    "]\n",
    "\n",
    "non_output_cols = df_all.columns.difference(output_cols)\n",
    "nan_input = df_all[non_output_cols].columns[df_all[non_output_cols].isnull().any()].tolist()\n",
    "\n",
    "df_imputed = df_all.copy()\n",
    "df_imputed[\"hours_beforesepsis\"] = df_imputed[\"hours_beforesepsis\"].fillna(0)\n",
    "df_imputed['gender'] = df_imputed['gender'].map({'M':0, 'F':1})\n",
    "\n",
    "for col in df_imputed.select_dtypes(include=['object']).columns:\n",
    "    df_imputed[col] = pd.to_numeric(df_imputed[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e60239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6fd410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_imputed[non_output_cols].drop(columns=[\"starttime\", \"endtime\", \"subject_id\"]).to_numpy(dtype=np.float32)\n",
    "y = df_imputed[output_cols].drop(columns=[\"fod\"]).to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalWindowDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y,\n",
    "        stay_ids,\n",
    "        times,\n",
    "        global_feat_mean,   # [F] computed from TRAIN SET ONLY\n",
    "        window_size=24,\n",
    "        horizon=1\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.global_mean = global_feat_mean\n",
    "        self.samples = []\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"stay_id\": stay_ids,\n",
    "            \"time\": times,\n",
    "            \"idx\": np.arange(len(stay_ids))\n",
    "        })\n",
    "\n",
    "        for stay_id, g in df.groupby(\"stay_id\"):\n",
    "            g = g.sort_values(\"time\")\n",
    "            idxs = g[\"idx\"].values\n",
    "            tvals = g[\"time\"].values\n",
    "\n",
    "            for i in range(window_size, len(idxs) - horizon):\n",
    "                hist = idxs[i - window_size:i]\n",
    "                target = idxs[i + horizon]\n",
    "                self.samples.append((hist, target, tvals[i - window_size:i]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hist_idx, target_idx, times = self.samples[idx]\n",
    "\n",
    "        X_seq = self.X[hist_idx].astype(float)   # [T, F]\n",
    "        y_target = self.y[target_idx].astype(float)\n",
    "\n",
    "        # 1️⃣ mask FIRST (raw)\n",
    "        mask = ~np.isnan(X_seq)\n",
    "\n",
    "        T, F = X_seq.shape\n",
    "        X_filled = np.zeros_like(X_seq)\n",
    "        delta = np.zeros_like(X_seq)\n",
    "\n",
    "        # 2️⃣ causal GRU-D style fill\n",
    "        for f in range(F):\n",
    "            last_val = self.global_mean[f]\n",
    "            last_time = times[0]\n",
    "\n",
    "            for t in range(T):\n",
    "                if mask[t, f]:\n",
    "                    delta[t, f] = 0.0\n",
    "                    last_val = X_seq[t, f]\n",
    "                    last_time = times[t]\n",
    "                    X_filled[t, f] = last_val\n",
    "                else:\n",
    "                    delta[t, f] = times[t] - last_time\n",
    "                    gamma = np.exp(-delta[t, f])  # simple decay\n",
    "                    X_filled[t, f] = gamma * last_val + (1 - gamma) * self.global_mean[f]\n",
    "                    last_val = X_filled[t, f]\n",
    "\n",
    "        return {\n",
    "            \"X\": torch.tensor(X_filled, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(mask.astype(float), dtype=torch.float32),\n",
    "            \"delta\": torch.tensor(delta, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(y_target, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X = pad_sequence([b[\"X\"] for b in batch], batch_first=True)\n",
    "    mask = pad_sequence([b[\"mask\"] for b in batch], batch_first=True)\n",
    "    delta = pad_sequence([b[\"delta\"] for b in batch], batch_first=True)\n",
    "    y = torch.stack([b[\"y\"] for b in batch])\n",
    "\n",
    "    return {\"X\": X, \"mask\": mask, \"delta\": delta, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttnPool(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.score = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, z, padding_mask):\n",
    "        # z: [B, T, D]\n",
    "        scores = self.score(z).squeeze(-1)  # [B, T]\n",
    "\n",
    "        # padding_mask: [B, T], 1 = valid, 0 = pad\n",
    "        scores = scores.masked_fill(padding_mask == 0, -1e9)\n",
    "\n",
    "        alpha = torch.softmax(scores, dim=1)\n",
    "        pooled = (z * alpha.unsqueeze(-1)).sum(dim=1)\n",
    "        return pooled\n",
    "\n",
    "class GRUDTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features,\n",
    "        hidden_size=64,\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        out_dim=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = n_features * 3\n",
    "        self.gru = nn.GRU(self.input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        self.to_dmodel = nn.Linear(hidden_size, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.attn_pool = TemporalAttnPool(d_model)\n",
    "        self.head = nn.Linear(d_model, out_dim)\n",
    "\n",
    "    def forward(self, x, mask, delta):\n",
    "        inp = torch.cat([x, mask, delta], dim=-1)\n",
    "        h, _ = self.gru(inp)\n",
    "\n",
    "        z = self.to_dmodel(h)\n",
    "\n",
    "        time_mask = (mask.sum(dim=-1) > 0)  # bool [B, T]\n",
    "\n",
    "        z = self.transformer(\n",
    "            z,\n",
    "            src_key_padding_mask=~time_mask\n",
    "        )\n",
    "\n",
    "        pooled = self.attn_pool(z, time_mask)\n",
    "        out = self.head(pooled)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfba49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Supports bf16: True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Supports bf16:\", torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90df6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_scaled = np.memmap(\n",
    "    'X_scaled2.dat',\n",
    "    dtype='float32',\n",
    "    mode='w+',\n",
    "    shape=(n_samples, n_features)\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X.astype(np.float32))   # FIT SEKALI, GLOBAL\n",
    "\n",
    "chunk_size = 100_000\n",
    "for start in range(0, n_samples, chunk_size):\n",
    "    end = min(start + chunk_size, n_samples)\n",
    "    X_scaled[start:end] = scaler.transform(\n",
    "        X[start:end].astype(np.float32)\n",
    "    )\n",
    "\n",
    "# target scaling\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.astype(np.float32))\n",
    "\n",
    "stay_ids = df_imputed['stay_id'].values\n",
    "times = df_imputed.groupby(\"stay_id\").cumcount().values\n",
    "\n",
    "global_feat_mean = np.nanmean(X_scaled, axis=0)\n",
    "global_feat_mean = np.nan_to_num(global_feat_mean, nan=0.0)\n",
    "\n",
    "dataset = TemporalWindowDataset(\n",
    "    X=X_scaled,\n",
    "    y=y_scaled,\n",
    "    stay_ids=stay_ids,\n",
    "    times=times,\n",
    "    global_feat_mean=global_feat_mean,\n",
    "    window_size=24,\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "val_ratio = 0.2\n",
    "n_total = len(dataset)\n",
    "n_val = int(n_total * val_ratio)\n",
    "n_train = n_total - n_val\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,\n",
    "    [n_train, n_val],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66e6cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda  | BF16 supported: True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, \" | BF16 supported:\", torch.cuda.is_bf16_supported())\n",
    "\n",
    "n_features = X_scaled.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = y_scaled.shape[1]\n",
    "\n",
    "model = GRUDTransformer(\n",
    "    n_features=X_scaled.shape[1],\n",
    "    hidden_size=64,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    out_dim=y_scaled.shape[1]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.1908 | Train per output: [0.18716806 0.11450574 0.13004689 0.10756511 0.25459883 0.14624625\n",
      " 0.08314896 0.44984046 0.24423419] | Val Loss: 0.1869 | Val per output: [0.1842378  0.11657601 0.12781377 0.10975344 0.24924178 0.14479917\n",
      " 0.08031132 0.43886927 0.23059319]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.1794 | Train per output: [0.17966814 0.11418217 0.12582032 0.1078416  0.2513497  0.14399204\n",
      " 0.07467324 0.39882758 0.21844211] | Val Loss: 0.1683 | Val per output: [0.1762729  0.11112966 0.11888427 0.10718183 0.24541065 0.13978374\n",
      " 0.06015815 0.35980946 0.19566399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Val]:  23%|██▎       | 268/1175 [01:02<05:34,  2.71it/s]                                                                                                      "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_losses_per_output = []\n",
    "\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        X_batch = batch[\"X\"].to(device)\n",
    "        mask_batch = batch[\"mask\"].to(device)\n",
    "        delta_batch = batch[\"delta\"].to(device)\n",
    "        y_batch = batch[\"y\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16, enabled=use_amp):\n",
    "            output = model(X_batch, mask_batch, delta_batch)  # [B, output_size]\n",
    "\n",
    "            # --- per-output loss pake criterion ---\n",
    "            losses_per_output = torch.stack([\n",
    "                criterion(output[:, i], y_batch[:, i])\n",
    "                for i in range(output.shape[1])\n",
    "            ])\n",
    "            loss = losses_per_output.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_losses_per_output.append(losses_per_output.detach().cpu().numpy())\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            loop.set_postfix({f\"L{i}\": f\"{l:.4f}\" for i, l in enumerate(losses_per_output)})\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    avg_train_losses_per_output = np.mean(train_losses_per_output, axis=0)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_losses_per_output = []\n",
    "\n",
    "    val_loop = tqdm(val_dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loop:\n",
    "            X_val = batch[\"X\"].to(device)\n",
    "            mask_val = batch[\"mask\"].to(device)\n",
    "            delta_val = batch[\"delta\"].to(device)\n",
    "            y_val = batch[\"y\"].to(device)\n",
    "\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16, enabled=use_amp):\n",
    "                val_out = model(X_val, mask_val, delta_val)\n",
    "\n",
    "                val_losses_batch = torch.stack([\n",
    "                    criterion(val_out[:, i], y_val[:, i])\n",
    "                    for i in range(val_out.shape[1])\n",
    "                ])\n",
    "                val_loss = val_losses_batch.mean()\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_losses_per_output.append(val_losses_batch.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    avg_val_losses_per_output = np.mean(val_losses_per_output, axis=0)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Train per output: {avg_train_losses_per_output} | \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "        f\"Val per output: {avg_val_losses_per_output}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3a45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
